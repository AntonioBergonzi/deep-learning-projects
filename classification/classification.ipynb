{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description of the procedure that we have followed"},{"metadata":{},"cell_type":"markdown","source":"We have adopted a progressive approach, starting from simple models (with few parameters) to more complex models; at each step we've tuned the model in order to evaluate its performances to the best.\nTherefore at the beginning we have tried models similar to the one seen at the laboratory sessions; for these structures, our guidelines have been the one aforementioned (from simple to complex), adding parameters if the previous model was not enough powerful to handle the classification well enough and adding dropout layers from regularization purposes. Moreover we tried to add regularization terms to the dense layers after the convolutional part, but all the networks we tried didn't perform better using this, so we dropped it.\nThe custom model we built was composed by some convolutional blocks (filters, relu, max-pooling), followed by a flatten layer and a fully connected layer. The convolutional block with which we reached the best performance had a depth of 5, a starting number of filter of 4 (doubling at each step) and a batch size of 32. Since we couldn't do better than 0.78, we switched to transfer learning.\nAt the beginning we started from the laboratory session's structure, thus using vgg16.\nThe problem with vgg was that we were not able to perform as we want; so we changed the feature extractor, selecting MobileNet, because of its high performances despite its simplicity (few parameters) that allow us to push our training also to most of the MobileNet layers.\nTo tune the models, the approach adopted has been the classic trial&error, guided by our perception of the model overfit/underfit properties given by the losses and the accuracies (train and validation ones), doing hyperparameter tuning.\nTo deal with overfitting we used two of the techniques seen during the lectures, i.e. Early Stopping (monitored on validation accuracy) and dropout layers.\nAfter we reached our peak performance, we tried to do better using bagging with 5 models, of similar structure of our best one, but we didn't manage to increase our final accuracy.\nThe following notebook is the one related to our best result in the competition, and all the hyperparameters' values can be found in the related section.\n* Giulio Alizoni - 10574760\n* Antonio Bergonzi - 10522307\n* Elia Bonazza - 10533395\n"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import regularizers\nfrom keras.applications.mobilenet import preprocess_input\n\n\nimport numpy as np\n\nimport pandas as pd\n\nimport json\n\nfrom datetime import datetime\n\nimport ntpath","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Environment setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"InteractiveShell.ast_node_interactivity = \"all\" \n\nSEED = 1234\ntf.random.set_seed(SEED)  \n\n\ncwd = '/kaggle/input'\n\n# the following is needed for running on colab\n\n#cwd = os.getcwd()\n\n#from google.colab import drive\n#drive.mount('/content/drive')\n\n#!unzip '/content/drive/My Drive/first_challenge_nn.zip' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting information about the GPUs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameters definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 3\nclasses = [None]\nimg_h = 256\nimg_w = 256\n\napply_data_augmentation = True\n\nFREEZE_UNTIL_TL = 3\n\nbs = 5\nlr = 2e-4\ndropout_rate = 0.3\nepochs_num = 100\n\nloss = tf.keras.losses.CategoricalCrossentropy()\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n\nmetrics = ['accuracy']\n\nearly_stop = True\n\npatience_steps = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**Setup for the data augmentation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training ImageDataGenerator object\nif apply_data_augmentation:\n    train_data_gen = ImageDataGenerator(rotation_range=10,\n                                        width_shift_range=10,\n                                        height_shift_range=10,\n                                        zoom_range=0.3,\n                                        horizontal_flip=True,\n                                        vertical_flip=True,\n                                        fill_mode='constant', #adding some pixels\n                                        cval=0, #costant value of those pixels\n                                        preprocessing_function=preprocess_input #preprocessing the data as the tl part prefers\n                                        )\nelse:\n    train_data_gen = ImageDataGenerator(rescale=1./255, \n                                       preprocessing_function=preprocess_input #preprocessing the data as the tl part prefers\n                                       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data retrieval as dataframe**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = os.path.join(cwd, 'artificial-neural-networks-and-deep-learning-2020/MaskDataset')\n\ntraining_dir = os.path.join(dataset_dir, 'training')\n\nwith open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n  dic = json.load(f)\n  \ndataframe = pd.DataFrame(dic.items())\ndataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\ndataframe[\"class\"] = dataframe[\"class\"].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shuffle of the data and split it into training and validation set;\nthe shuffle is needed in order to be sure to have in all of the set randomly selected samples from every class. We decided not to test in local, since the test competition we thought was enough and having the notebook on kaggle makes it easy to submit the .csv file.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_validation(dataframe, SEED):  \n  df_len = len(dataframe)\n\n  dataframe = dataframe.sample(frac=1, random_state=SEED).reset_index(drop=True)\n\n  train_end = int(df_len*0.9)\n  valid_start = train_end\n\n  train_df = dataframe[ : train_end]\n  valid_df = dataframe[valid_start :]\n  return [train_df, valid_df]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating the samples for each set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_flow(data_gen, dataframe, directory, bs, img_h, img_w, num_classes, SEED=None):\n\n  gen = data_gen.flow_from_dataframe(dataframe,\n                                                directory,\n                                                batch_size=bs,\n                                                class_mode='categorical',\n                                                image_size=(img_h, img_w),\n                                                target_size=(img_h, img_w),\n                                                shuffle=True,\n                                                seed=SEED)\n  dataset = tf.data.Dataset.from_generator(lambda: gen,\n                                                output_types=(tf.float32, tf.float32),\n                                                output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n  dataset = dataset.repeat()\n  return dataset, len(gen)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model definition"},{"metadata":{},"cell_type":"markdown","source":"**Tranfer Learning model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tl = tf.keras.applications.MobileNet(include_top=False, input_shape=[img_w, img_h, 3])\nfreeze_until = FREEZE_UNTIL_TL # layer from which we want to fine-tune\n    \nfor layer in tl.layers[:freeze_until]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Custom model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\n    \nmodel.add(tl)\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dropout(rate=dropout_rate))\nmodel.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model training"},{"metadata":{},"cell_type":"markdown","source":"**Definition of the callbacks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = []\n\n# Early Stopping\n# --------------\n\nif early_stop:\n    es_callback = tf.keras.callbacks.EarlyStopping(patience=patience_steps, \n                                                   monitor=\"val_accuracy\",\n                                                  restore_best_weights = True)\n    callbacks.append(es_callback)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model fit**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_df, valid_df = create_validation(dataframe, SEED)\ntrain_dataset, len_train= create_flow(train_data_gen, train_df, training_dir, bs, img_h, img_w, num_classes, SEED)\nvalid_dataset, len_valid = create_flow(train_data_gen, valid_df, training_dir, bs, img_h, img_w, num_classes, SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=train_dataset,\n        epochs=epochs_num,\n        steps_per_epoch=len_train,\n        validation_data=valid_dataset,\n        validation_steps=len_valid,\n        callbacks=callbacks\n        )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction on new data"},{"metadata":{},"cell_type":"markdown","source":"**Data preparation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = os.path.join(dataset_dir, 'test')\ntest_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nimg_filenames = next(os.walk(test_dir))[2]\ntest_df = pd.DataFrame(img_filenames)\ntest_df['class'] = '0'\ntest_df.rename(columns={0:\"filename\"},\n               inplace=True)\ntest_gen = test_data_gen.flow_from_dataframe(test_df, \n                                             test_dir,\n                                             target_size=(img_h, img_w), \n                                                 color_mode='rgb',\n                                                 class_mode='categorical',\n                                                 classes = None,\n                                                 batch_size=1,\n                                                 shuffle=False)\ntest_gen.reset()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predictions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\nresults = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Collecting the predictions as python dictionary**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimages = test_gen.filenames\ni = 0\n\nfor p in predictions:\n  prediction = np.argmax(p)\n  image_name = ntpath.basename(images[i])\n  results[image_name] = str(prediction)\n  i = i + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Collecting the prediction as .csv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_csv(results, results_dir='./'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')\n\n\n            \ncreate_csv(results, '/kaggle/working/')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}