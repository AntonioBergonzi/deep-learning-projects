{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Description of the procedure that we have followed"]},{"cell_type":"markdown","metadata":{},"source":["We have adopted a progressive approach, starting from simple models (with few parameters) to more complex models; at each step we've tuned the model in order to evaluate its performances to the best.<br>\n","Therefore at the beginning we have tried models similar to the one seen at the laboratory sessions; for these structures, our guidelines have been the one aforementioned (from simple to complex), adding parameters if the previous model was not enough powerful to handle the classification well enough and adding dropout layers from regularization purposes. Moreover we tried to add regularization terms to the dense layers after the convolutional part, but all the networks we tried didn't perform better using this, so we dropped it.\n","\n","The custom model we built was composed by some convolutional blocks (filters, relu, max-pooling), followed by a flatten layer and a fully connected layer. The convolutional block with which we reached the best performance had a depth of 5, a starting number of filter of 4 (doubling at each step) and a batch size of 32. Since we couldn't do better than 0.78, we switched to transfer learning.<br>\n","At the beginning we started from the laboratory session's structure, thus using vgg16.<br>\n","The problem with vgg was that we were not able to perform as we wanted; so we changed the feature extractor, selecting MobileNet, because of its high performances despite its simplicity (few parameters) that allowed us to push our training also to most of the MobileNet layers.\n","\n","To tune the models, the approach adopted has been the classic trial&error, guided by our perception of the model overfit/underfit properties given by the losses and the accuracies (train and validation ones), doing hyperparameter tuning.<br>\n","To deal with overfitting we used two of the techniques seen during the lectures, i.e. Early Stopping (monitored on validation accuracy) and dropout layers.<br>\n","After we reached our peak performance, we tried to do better using bagging with 5 models, of similar structure of our best one, but we didn't manage to increase our final accuracy.\n","The following notebook is the one related to our best result in the competition, and all the hyperparameters' values can be found in the related section.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from IPython.core.interactiveshell import InteractiveShell\n","\n","import os\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import regularizers\n","from keras.applications.mobilenet import preprocess_input\n","\n","\n","import numpy as np\n","\n","import pandas as pd\n","\n","import json\n","\n","from datetime import datetime\n","\n","import ntpath"]},{"cell_type":"markdown","metadata":{},"source":["# Environment setup"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["InteractiveShell.ast_node_interactivity = \"all\" \n","\n","SEED = 1234\n","tf.random.set_seed(SEED)  \n","\n","\n","cwd = '/kaggle/input'\n","\n","# the following is needed for running on colab\n","\n","#cwd = os.getcwd()\n","\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","#!unzip '/content/drive/My Drive/first_challenge_nn.zip' "]},{"cell_type":"markdown","metadata":{},"source":["**Getting information about the GPUs**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    print(e)\n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters definition"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_classes = 3\n","classes = [None]\n","img_h = 256\n","img_w = 256\n","\n","apply_data_augmentation = True\n","\n","FREEZE_UNTIL_TL = 3\n","\n","bs = 5\n","lr = 2e-4\n","dropout_rate = 0.3\n","epochs_num = 100\n","\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","metrics = ['accuracy']\n","\n","early_stop = True\n","\n","patience_steps = 10"]},{"cell_type":"markdown","metadata":{},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["**Setup for the data augmentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create training ImageDataGenerator object\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='constant', #adding some pixels\n","                                        cval=0, #costant value of those pixels\n","                                        preprocessing_function=preprocess_input #preprocessing the data as the tl part prefers\n","                                        )\n","else:\n","    train_data_gen = ImageDataGenerator(rescale=1./255, \n","                                       preprocessing_function=preprocess_input #preprocessing the data as the tl part prefers\n","                                       )"]},{"cell_type":"markdown","metadata":{},"source":["**Data retrieval as dataframe**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_dir = os.path.join(cwd, 'artificial-neural-networks-and-deep-learning-2020/MaskDataset')\n","\n","training_dir = os.path.join(dataset_dir, 'training')\n","\n","with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n","  dic = json.load(f)\n","  \n","dataframe = pd.DataFrame(dic.items())\n","dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n","dataframe[\"class\"] = dataframe[\"class\"].astype(str)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Shuffle of the data and split it into training and validation set;\n","the shuffle is needed in order to be sure to have in all of the set randomly selected samples from every class. We decided not to test in local, since the test competition we thought was enough and having the notebook on kaggle makes it easy to submit the .csv file.**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_validation(dataframe, SEED):  \n","  df_len = len(dataframe)\n","\n","  dataframe = dataframe.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","\n","  train_end = int(df_len*0.9)\n","  valid_start = train_end\n","\n","  train_df = dataframe[ : train_end]\n","  valid_df = dataframe[valid_start :]\n","  return [train_df, valid_df]\n"]},{"cell_type":"markdown","metadata":{},"source":["**Creating the samples for each set**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_flow(data_gen, dataframe, directory, bs, img_h, img_w, num_classes, SEED=None):\n","\n","  gen = data_gen.flow_from_dataframe(dataframe,\n","                                                directory,\n","                                                batch_size=bs,\n","                                                class_mode='categorical',\n","                                                image_size=(img_h, img_w),\n","                                                target_size=(img_h, img_w),\n","                                                shuffle=True,\n","                                                seed=SEED)\n","  dataset = tf.data.Dataset.from_generator(lambda: gen,\n","                                                output_types=(tf.float32, tf.float32),\n","                                                output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","  dataset = dataset.repeat()\n","  return dataset, len(gen)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model definition"]},{"cell_type":"markdown","metadata":{},"source":["**Tranfer Learning model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tl = tf.keras.applications.MobileNet(include_top=False, input_shape=[img_w, img_h, 3])\n","freeze_until = FREEZE_UNTIL_TL # layer from which we want to fine-tune\n","    \n","for layer in tl.layers[:freeze_until]:\n","    layer.trainable = False"]},{"cell_type":"markdown","metadata":{},"source":["**Custom model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = tf.keras.Sequential()\n","    \n","model.add(tl)\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Model training"]},{"cell_type":"markdown","metadata":{},"source":["**Definition of the callbacks**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["callbacks = []\n","\n","# Early Stopping\n","# --------------\n","\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(patience=patience_steps, \n","                                                   monitor=\"val_accuracy\",\n","                                                  restore_best_weights = True)\n","    callbacks.append(es_callback)\n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["**Model fit**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","train_df, valid_df = create_validation(dataframe, SEED)\n","train_dataset, len_train= create_flow(train_data_gen, train_df, training_dir, bs, img_h, img_w, num_classes, SEED)\n","valid_dataset, len_valid = create_flow(train_data_gen, valid_df, training_dir, bs, img_h, img_w, num_classes, SEED)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.fit(x=train_dataset,\n","        epochs=epochs_num,\n","        steps_per_epoch=len_train,\n","        validation_data=valid_dataset,\n","        validation_steps=len_valid,\n","        callbacks=callbacks\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction on new data"]},{"cell_type":"markdown","metadata":{},"source":["**Data preparation**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_dir = os.path.join(dataset_dir, 'test')\n","test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","img_filenames = next(os.walk(test_dir))[2]\n","test_df = pd.DataFrame(img_filenames)\n","test_df['class'] = '0'\n","test_df.rename(columns={0:\"filename\"},\n","               inplace=True)\n","test_gen = test_data_gen.flow_from_dataframe(test_df, \n","                                             test_dir,\n","                                             target_size=(img_h, img_w), \n","                                                 color_mode='rgb',\n","                                                 class_mode='categorical',\n","                                                 classes = None,\n","                                                 batch_size=1,\n","                                                 shuffle=False)\n","test_gen.reset()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Predictions**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n","results = {}"]},{"cell_type":"markdown","metadata":{},"source":["**Collecting the predictions as python dictionary**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","images = test_gen.filenames\n","i = 0\n","\n","for p in predictions:\n","  prediction = np.argmax(p)\n","  image_name = ntpath.basename(images[i])\n","  results[image_name] = str(prediction)\n","  i = i + 1"]},{"cell_type":"markdown","metadata":{},"source":["**Collecting the prediction as .csv**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')\n","\n","\n","            \n","create_csv(results, '/kaggle/working/')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
